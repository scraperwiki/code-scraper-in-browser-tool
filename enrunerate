#!/bin/bash

PARAM=$1
FLOCK="flock -n ./running.flock ./code/scraper"
REGEXP="./code/scraper"

# Parameters:
# "run" to actually launch scraper if not already
# Otherwise just return status

# Disable buffering of stdout/stderr
# XXX can we do this in other languages?
export PYTHONUNBUFFERED=1
# Make output encode as UTF-8, as that is what the browser is expecting
export PYTHONIOENCODING=utf_8

# Check already running
# XXX this won't work on multiple servers without affinity of some kind
# perhaps instead can rely on the flock?
if pgrep -f "$REGEXP" >/dev/null
then
    if [ "$PARAM" == "stop" ]
    then
        # Try and kill it kindly, so SQLite will close up properly
        pkill -f "$REGEXP"
        if pgrep -f "$REGEXP"
        then
            sleep 1
            pkill -f "$REGEXP"
            if pgrep -f "$REGEXP"
            then
                # Wait a while to give it time
                sleep 10
                if pgrep -f "$REGEXP"
                then
                    # Give up
                    pkill -9 -f "$REGEXP"
                    if pgrep -f "$REGEXP"
                    then
                        echo -n "failed to kill"
                    fi
                fi
            fi
        fi
        echo -n "nothing"
        exit 0
    else
        echo -n "running"
        exit 0
    fi
fi

# Run in background, redirecting to logfile
if [ "$PARAM" == "run" ]
then
    mkdir -p logs/

    # Use flock to lock the launch, to be sure we only run one copy
    # (we can ignore errors - it is already running and we only want one at a time!)
    # XXX does flock really work on glusterfs?
    $FLOCK >logs/out 2>&1 &

    # Say it is now running
    echo -n "running"
    exit 0
fi

# Say whether it is running
echo -n "nothing"


